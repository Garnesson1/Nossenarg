{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciting Demography on large datasets using NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to using NLP and machine learning on keywords related to website searches. We will use this to predict demgraphic groups in our data, more specifically on age and gender. The dataset being 1.5 GB large will require some transformations abd processing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('/Users/JohanLg/Documents/My Documents/ESCP/Kurser/Vår/Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.sample(frac=0.01, replace=False, random_state=1)\n",
    "\n",
    "# Large dataset, sample 1% for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                                           keywords  age sex\n",
      "244242    392037  des:1;protection:1;offre:1;risques:1;preventio...   39   M\n",
      "4143485  1782381                                          annonce:3   45   F\n",
      "5262074   433807  relation:1;apres:1;avec:1;consentante:1;sexuel...   48   F\n",
      "1803744   181848               terrasse:1;auto:1;accident:1;ville:1   52   M\n",
      "2110117   386562  livre:1;3eme:1;transmath:1;affich:1;forum:1;co...   49   F\n",
      "\n",
      "\n",
      "Number of occurances 641878\n"
     ]
    }
   ],
   "source": [
    "## Dropping rows with null values\n",
    "Cleantr = df.dropna()\n",
    "print(Cleantr.head())\n",
    "print(\"\\n\")\n",
    "print(\"Number of occurances %d8\" % len(Cleantr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a clean dataset,the idea is to \"untangle\" the keywords so that we can apply standard NLP techniques like TF-IDF. We want to create a dictonary of all the words used in the keywords seaches. First step is to create the dictionary, where we will\n",
    "\n",
    "1. Split the keyword column into word and count\n",
    "2. Multiply the word by its count\n",
    "3. Create a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting keywords\n",
    "\n",
    "def split_keywords_expand(x):\n",
    "    result = \"\"\n",
    "    if isinstance(x, str):\n",
    "        for word_count in x.split(\";\"):\n",
    "            if len(word_count.split(\":\")) == 2:\n",
    "                word, count = word_count.split(\":\")\n",
    "            else:\n",
    "                word = word_count\n",
    "                count = 1\n",
    "            for _ in range(int(count)):\n",
    "                result += \" \" + word\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cleantr['keywords']=Cleantr['keywords'].apply(split_keywords_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244242</th>\n",
       "      <td>392037</td>\n",
       "      <td>des protection offre risques prevention charge</td>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143485</th>\n",
       "      <td>1782381</td>\n",
       "      <td>annonce annonce annonce</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262074</th>\n",
       "      <td>433807</td>\n",
       "      <td>relation apres avec consentante sexuelle actu...</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803744</th>\n",
       "      <td>181848</td>\n",
       "      <td>terrasse auto accident ville</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110117</th>\n",
       "      <td>386562</td>\n",
       "      <td>livre 3eme transmath affich forum corrige</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                           keywords  age sex\n",
       "244242    392037     des protection offre risques prevention charge   39   M\n",
       "4143485  1782381                            annonce annonce annonce   45   F\n",
       "5262074   433807   relation apres avec consentante sexuelle actu...   48   F\n",
       "1803744   181848                       terrasse auto accident ville   52   M\n",
       "2110117   386562          livre 3eme transmath affich forum corrige   49   F"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleantr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Create Dictionary \n",
    "\n",
    "We see that this dataframe shows all keyword in its multiplied form. Now we shall apply NLP by:\n",
    "\n",
    "1. Removing Stem-Stop words.\n",
    "2. Counting ALL occurances of words.\n",
    "3. Using the counts or weighted counts in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/JohanLg/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "stemmer = stem.SnowballStemmer('french')\n",
    "stopwords = set(stopwords.words('french'))\n",
    "\n",
    "def review_messages(msg):\n",
    "    # converting messages to lowercase\n",
    "    msg = msg.lower()\n",
    "    # removing stopwords\n",
    "    msg = [word for word in msg.split() if word not in stopwords]\n",
    "    # using a stemmer\n",
    "    msg = \" \".join([stemmer.stem(word) for word in msg])\n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s =Cleantr['keywords'].apply(review_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a clean list of words ready to be made into a dictionary. First we split our data and make the train-sets cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Cleantr['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split data in test and training dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(s,  Y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_count = CountVectorizer()\n",
    "from sklearn.metrics import accuracy_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dic = vectorizer_count.fit(X_train)\n",
    "    # Creates the dictionary of words and word counts\n",
    "\n",
    "\n",
    "X_train_count = vectorizer_count.fit_transform(X_train)\n",
    "    # Creates a numeric array of these words for ml models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "dic_tdif = vectorizer_tfidf.fit(X_train)\n",
    "X_train_tfidf=dic_tdif.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.271060    26625\n",
      "10.865595     5425\n",
      "10.577913     2561\n",
      "10.354770     1734\n",
      "10.172448     1182\n",
      "Name: 0, dtype: int64\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(dic_tdif.idf_)[0].value_counts().head())\n",
    "print(type(dic_tdif.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_count.fit(X_train)\n",
    "X_trainA =vectorizer_count.transform(X_train)\n",
    "X_testA =vectorizer_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeleval(stuff,stuff1,stuff2,stuff4):\n",
    "    models = [stuff1,stuff2,stuff2,stuff4]\n",
    "    for model1 in models:\n",
    "        model = model1\n",
    "        Algo = model.fit(X_trainA, y_train)\n",
    "        predictions = Algo.predict(X_testA)\n",
    "    \n",
    "        print( \"-----%s-----\" % model1)\n",
    "        print(\"\\n\")\n",
    "        print(confusion_matrix(y_test, predictions))\n",
    "        print( \"\\n\")\n",
    "        print(\"Accuracy Score ; %8.2f\" % (accuracy_score(predictions, y_test)*100))\n",
    "        print( \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)-----\n",
      "\n",
      "\n",
      "[[1343 1610]\n",
      " [1038 2428]]\n",
      "\n",
      "\n",
      "Accuracy Score ;    58.75\n",
      "\n",
      "\n",
      "-----MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)-----\n",
      "\n",
      "\n",
      "[[ 706 2247]\n",
      " [ 387 3079]]\n",
      "\n",
      "\n",
      "Accuracy Score ;    58.97\n",
      "\n",
      "\n",
      "-----MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)-----\n",
      "\n",
      "\n",
      "[[ 706 2247]\n",
      " [ 387 3079]]\n",
      "\n",
      "\n",
      "Accuracy Score ;    58.97\n",
      "\n",
      "\n",
      "-----XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)-----\n",
      "\n",
      "\n",
      "[[ 606 2347]\n",
      " [ 258 3208]]\n",
      "\n",
      "\n",
      "Accuracy Score ;    59.42\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "modeleval(svm, RandomForestClassifier(), MultinomialNB(), xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestModelGender = RandomForestClassifier()\n",
    "mlb_tfidf = BestModelGender.fit(X_trainA, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(s, Cleantr['age'], test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_tfidf.fit(X_train1)\n",
    "X_train1 =vectorizer_tfidf.transform(X_train1)\n",
    "X_test1 =vectorizer_tfidf.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin = linear_model.Ridge(alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modeleval_age(stuff,stuff1,stuff2,stuff4):\n",
    "    models = [stuff1,stuff2,stuff2,stuff4]\n",
    "    for model1 in models:\n",
    "        model = model1\n",
    "        Algo = model.fit(X_train1, y_train1)\n",
    "        pred = Algo.predict(X_test1)\n",
    "    \n",
    "        print( \"-----%s-----\" % model1)\n",
    "        print(\"\\n\")\n",
    "        print('Mean Absolute Error:', metrics.mean_absolute_error(y_test1, pred))  \n",
    "        print('Mean Squared Error:', metrics.mean_squared_error(y_test1, pred))  \n",
    "        print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test1, pred)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "             silent=True, subsample=1)-----\n",
      "\n",
      "\n",
      "Mean Absolute Error: 10.355412299136429\n",
      "Mean Squared Error: 162.59158551531175\n",
      "Root Mean Squared Error: 12.75114055742904\n",
      "\n",
      "\n",
      "-----RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)-----\n",
      "\n",
      "\n",
      "Mean Absolute Error: 13.018382925689359\n",
      "Mean Squared Error: 276.52827543231035\n",
      "Root Mean Squared Error: 16.629139347311703\n",
      "\n",
      "\n",
      "-----RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)-----\n",
      "\n",
      "\n",
      "Mean Absolute Error: 12.822246455834241\n",
      "Mean Squared Error: 267.2400685465026\n",
      "Root Mean Squared Error: 16.34747896608228\n",
      "\n",
      "\n",
      "-----MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)-----\n",
      "\n",
      "\n",
      "Mean Absolute Error: 11.044711014176663\n",
      "Mean Squared Error: 196.2816638105624\n",
      "Root Mean Squared Error: 14.010055810401413\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modeleval_age(lin , xgb.XGBRegressor(), RandomForestClassifier(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BestModelAge = xgb.XGBRegressor()\n",
    "xg_reg = BestModelAge.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting TEST set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF1 = []\n",
    "DF2 = []\n",
    "\n",
    "for chunk in pd.read_csv('test.csv', chunksize = 10000):\n",
    "    chunk = chunk['keywords']\n",
    "    chunk = chunk.dropna()\n",
    "    chunk = chunk.apply(split_keywords_expand)\n",
    "    hot = vectorizer_count.transform(chunk)\n",
    "    hot1 =vectorizer_tfidf.transform(chunk)\n",
    "    Gender = mlb_tfidf.predict(hot) \n",
    "    Age = xg_reg.predict(hot1)\n",
    "    DF1.append(Gender)\n",
    "    DF2.append(Age) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_G = []\n",
    "Final_A = []\n",
    "for i in range(0,len(DF1)):\n",
    "        G = pd.DataFrame(DF1[i])\n",
    "        A = pd.DataFrame(DF2[i])\n",
    "        Final_G.append(G)\n",
    "        Final_A.append(A)\n",
    "Final = pd.concat(Final_G) \n",
    "Final['Age'] = pd.concat(Final_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>46.195633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>45.448387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>45.448387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>45.788342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>46.218491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748738</th>\n",
       "      <td>1565</td>\n",
       "      <td>M</td>\n",
       "      <td>45.448387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748739</th>\n",
       "      <td>1566</td>\n",
       "      <td>M</td>\n",
       "      <td>45.448387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748740</th>\n",
       "      <td>1567</td>\n",
       "      <td>M</td>\n",
       "      <td>44.616375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748741</th>\n",
       "      <td>1568</td>\n",
       "      <td>M</td>\n",
       "      <td>45.448387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748742</th>\n",
       "      <td>1569</td>\n",
       "      <td>F</td>\n",
       "      <td>44.690350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748743 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  0        Age\n",
       "0            0  M  46.195633\n",
       "1            1  M  45.448387\n",
       "2            2  M  45.448387\n",
       "3            3  M  45.788342\n",
       "4            4  M  46.218491\n",
       "...        ... ..        ...\n",
       "2748738   1565  M  45.448387\n",
       "2748739   1566  M  45.448387\n",
       "2748740   1567  M  44.616375\n",
       "2748741   1568  M  45.448387\n",
       "2748742   1569  F  44.690350\n",
       "\n",
       "[2748743 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final.to_csv('Final_Predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
